#!/bin/bash
#
# This file should not be executed, instead it should be
# sourced by the download script in each utility directory

# Based on gcc's download_prerequisites script

set -o pipefail

die() {
    echo "error: $@" >&2
    exit 1
}

# Supply this function with the list of URLs to download
do_download() {
    mkdir -p src
    pushd src

    if type wget > /dev/null ; then
	# "wget -N -c" : Only download the file if it does not
	# already exists locally, or if the size is different
	# locally, or if the timestamp on the server is newer.
	fetch='wget -N -c'
    else
	if type curl > /dev/null; then
	    fetch='curl -LO'
	else
	    die "Unable to find wget or curl"
	fi
    fi

    for ar in $@
    do
        ${fetch} "${ar}"    \
	    || die "Cannot download $ar"
	tar -xf "$(basename ${ar})" \
	    || die "Cannot extract $(basename ${ar})"
    done
    unset ar
    popd
}
